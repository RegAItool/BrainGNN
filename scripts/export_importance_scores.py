#!/usr/bin/env python3
"""
è‡ªåŠ¨å¯¼å‡ºBrainGNNé‡è¦æ€§åˆ†æ•°
ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­æå–æ¯ä¸ªROIçš„é‡è¦æ€§åˆ†æ•°ï¼Œç”¨äºè„‘å›¾è°±å¯è§†åŒ–
"""

import torch
import numpy as np
import os
import pickle
from torch_geometric.data import DataLoader
import argparse
from net.braingnn import Network
from imports.ABIDEDataset import ABIDEDataset
from imports.utils import train_val_test_split

def load_trained_model(model_path, args):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model = Network(args.indim, args.ratio, args.nclass)
    
    if os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location='cpu')
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
        return model
    else:
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None

def extract_importance_scores(model, dataloader, device='cpu'):
    """æå–é‡è¦æ€§åˆ†æ•°"""
    model.eval()
    all_scores1 = []
    all_scores2 = []
    all_predictions = []
    all_labels = []
    
    print("ğŸ” æ­£åœ¨æå–é‡è¦æ€§åˆ†æ•°...")
    
    with torch.no_grad():
        for batch in dataloader:
            batch = batch.to(device)
            
            # å‰å‘ä¼ æ’­ï¼Œè·å–åˆ†æ•°
            output, _, _, score1, score2 = model(batch.x, batch.edge_index, 
                                                batch.batch, batch.edge_attr, batch.pos)
            
            # æ”¶é›†åˆ†æ•°
            all_scores1.append(score1.cpu().numpy())
            all_scores2.append(score2.cpu().numpy())
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
            pred = output.argmax(dim=1)
            all_predictions.append(pred.cpu().numpy())
            all_labels.append(batch.y.cpu().numpy())
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    scores1 = np.concatenate(all_scores1, axis=0)  # shape: (n_samples, n_rois)
    scores2 = np.concatenate(all_scores2, axis=0)  # shape: (n_samples, n_rois)
    predictions = np.concatenate(all_predictions, axis=0)
    labels = np.concatenate(all_labels, axis=0)
    
    return scores1, scores2, predictions, labels

def calculate_roi_importance(scores1, scores2, predictions, labels, method='mean'):
    """åªç”¨ç¬¬ä¸€å±‚åˆ†æ•°è®¡ç®—æ¯ä¸ªROIçš„é‡è¦æ€§åˆ†æ•°"""
    print(f"ğŸ“Š è®¡ç®—ROIé‡è¦æ€§åˆ†æ•° (æ–¹æ³•: {method}, åªç”¨ç¬¬ä¸€å±‚)...")
    correct_mask = (predictions == labels)
    print(f"   æ­£ç¡®é¢„æµ‹æ ·æœ¬æ•°: {np.sum(correct_mask)}/{len(predictions)}")
    if method == 'mean':
        roi_importance1 = np.mean(scores1[correct_mask], axis=0)
    elif method == 'weighted':
        confidence = np.max(scores1[correct_mask], axis=1)
        weights = confidence / np.sum(confidence)
        roi_importance1 = np.average(scores1[correct_mask], axis=0, weights=weights)
    elif method == 'max':
        roi_importance1 = np.max(scores1[correct_mask], axis=0)
    roi_importance = roi_importance1
    roi_importance2 = None
    return roi_importance, roi_importance1, roi_importance2

def save_importance_scores(roi_importance, roi_importance1, roi_importance2, 
                          scores1, scores2, predictions, labels, save_dir='./importance_scores'):
    """ä¿å­˜é‡è¦æ€§åˆ†æ•°"""
    os.makedirs(save_dir, exist_ok=True)
    
    # ä¿å­˜ä¸»è¦çš„é‡è¦æ€§åˆ†æ•°
    np.save(os.path.join(save_dir, 'roi_importance.npy'), roi_importance)
    np.save(os.path.join(save_dir, 'roi_importance_layer1.npy'), roi_importance1)
    
    # ä¿å­˜åŸå§‹åˆ†æ•°æ•°æ®
    np.save(os.path.join(save_dir, 'all_scores_layer1.npy'), scores1)
    
    # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾
    all_predictions = predictions
    all_labels = labels
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'n_samples': len(predictions),
        'n_correct': np.sum(predictions == labels),
        'accuracy': np.mean(predictions == labels),
        'roi_importance_shape': roi_importance.shape,
        'score1_shape': scores1.shape
    }
    
    with open(os.path.join(save_dir, 'stats.pkl'), 'wb') as f:
        pickle.dump(stats, f)
    
    print(f"ğŸ’¾ é‡è¦æ€§åˆ†æ•°å·²ä¿å­˜åˆ°: {save_dir}")
    print(f"   - ROIé‡è¦æ€§åˆ†æ•°: {roi_importance.shape}")
    print(f"   - å‡†ç¡®ç‡: {stats['accuracy']:.3f}")
    print(f"   - æ­£ç¡®é¢„æµ‹æ ·æœ¬: {stats['n_correct']}/{stats['n_samples']}")

def main():
    parser = argparse.ArgumentParser(description='å¯¼å‡ºBrainGNNé‡è¦æ€§åˆ†æ•°')
    parser.add_argument('--model_path', type=str, default='./model/best_model.pth',
                       help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„')
    parser.add_argument('--data_path', type=str, default='./data/ABIDE_pcp/cpac/filt_noglobal',
                       help='æ•°æ®è·¯å¾„')
    parser.add_argument('--save_dir', type=str, default='./importance_scores',
                       help='ä¿å­˜é‡è¦æ€§åˆ†æ•°çš„ç›®å½•')
    parser.add_argument('--method', type=str, default='mean', 
                       choices=['mean', 'weighted', 'max'],
                       help='è®¡ç®—ROIé‡è¦æ€§çš„æ–¹æ³•')
    parser.add_argument('--batch_size', type=int, default=100,
                       help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--device', type=str, default='cpu',
                       help='è®¾å¤‡ (cpu/cuda)')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--indim', type=int, default=200, help='è¾“å…¥ç»´åº¦')
    parser.add_argument('--ratio', type=float, default=0.5, help='poolingæ¯”ä¾‹')
    parser.add_argument('--nclass', type=int, default=2, help='ç±»åˆ«æ•°')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹å¯¼å‡ºBrainGNNé‡è¦æ€§åˆ†æ•°...")
    
    # 1. åŠ è½½æ•°æ®
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    dataset = ABIDEDataset(args.data_path, 'ABIDE')
    dataset.data.y = dataset.data.y.squeeze()
    dataset.data.x[dataset.data.x == float('inf')] = 0
    
    # è·å–æ•°æ®åˆ†å‰²
    tr_index, val_index, te_index = train_val_test_split(fold=0)
    train_dataset = dataset[tr_index]
    val_dataset = dataset[val_index]
    test_dataset = dataset[te_index]
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)
    
    # 3. åŠ è½½æ¨¡å‹
    model = load_trained_model(args.model_path, args)
    if model is None:
        return
    
    model = model.to(args.device)
    
    # 4. æå–é‡è¦æ€§åˆ†æ•°
    scores1, scores2, predictions, labels = extract_importance_scores(model, test_loader, args.device)
    
    # 5. è®¡ç®—ROIé‡è¦æ€§
    roi_importance, roi_importance1, roi_importance2 = calculate_roi_importance(
        scores1, scores2, predictions, labels, args.method)
    
    # 6. ä¿å­˜ç»“æœ
    save_importance_scores(roi_importance, roi_importance1, roi_importance2,
                          scores1, scores2, predictions, labels, args.save_dir)
    
    print("âœ… é‡è¦æ€§åˆ†æ•°å¯¼å‡ºå®Œæˆï¼")
    print(f"ğŸ“Š å‰10ä¸ªROIçš„é‡è¦æ€§åˆ†æ•°:")
    top_indices = np.argsort(roi_importance)[-10:][::-1]
    for i, idx in enumerate(top_indices):
        print(f"   ROI {idx:3d}: {roi_importance[idx]:.4f}")

if __name__ == '__main__':
    main() 