#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Publication Quality Brain Visualization
Using ParaView, BrainNet Viewer, and Brainrender for high-impact journal publications
"""

import numpy as np
import nibabel as nib
import pandas as pd
import json
import os
from pathlib import Path
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist, squareform
import vtk
from vtk.util.numpy_support import numpy_to_vtk

class PublicationQualityBrainViz:
    """å‘è¡¨è´¨é‡è„‘å›¾å¯è§†åŒ–ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.setup_brain_data()
        self.setup_output_dirs()
        self.pain_threshold = 0.3  # æ¿€æ´»é˜ˆå€¼
        
    def setup_brain_data(self):
        """è®¾ç½®åŸºäºBrainGNNç»“æœçš„è„‘åŒºæ•°æ®"""
        
        # BrainGNNå…³é”®ç»“æœ - ç–¼ç—›vséç–¼ç—›çš„æ¿€æ´»å·®å¼‚
        self.brain_regions = {
            # === ç–¼ç—›å¢å¼ºæ¿€æ´»åŒºåŸŸ ===
            'Cerebelum_Crus1_R': {
                'aal_id': 104, 'mni_coords': [28, -77, -33], 'activation': 0.601,
                'network': 'sensorimotor', 'hemisphere': 'R', 'lobe': 'cerebellum',
                'description': 'Primary sensorimotor integration during pain'
            },
            'Cerebelum_Crus1_L': {
                'aal_id': 103, 'mni_coords': [-28, -77, -33], 'activation': 0.438,
                'network': 'sensorimotor', 'hemisphere': 'L', 'lobe': 'cerebellum',
                'description': 'Bilateral cerebellar coordination'
            },
            'Occipital_Mid_R': {
                'aal_id': 54, 'mni_coords': [31, -87, 11], 'activation': 0.528,
                'network': 'visual', 'hemisphere': 'R', 'lobe': 'occipital',
                'description': 'Visual-spatial pain processing'
            },
            'Occipital_Sup_R': {
                'aal_id': 52, 'mni_coords': [20, -93, 15], 'activation': 0.528,
                'network': 'visual', 'hemisphere': 'R', 'lobe': 'occipital',
                'description': 'Enhanced visual attention to pain'
            },
            'Occipital_Mid_L': {
                'aal_id': 53, 'mni_coords': [-31, -87, 11], 'activation': 0.385,
                'network': 'visual', 'hemisphere': 'L', 'lobe': 'occipital',
                'description': 'Bilateral visual processing'
            },
            'ParaHippocampal_L': {
                'aal_id': 39, 'mni_coords': [-24, -7, -21], 'activation': 0.120,
                'network': 'limbic', 'hemisphere': 'L', 'lobe': 'temporal',
                'description': 'Pain memory encoding'
            },
            'Amygdala_R': {
                'aal_id': 42, 'mni_coords': [25, -1, -20], 'activation': 0.080,
                'network': 'limbic', 'hemisphere': 'R', 'lobe': 'temporal',
                'description': 'Emotional response to pain'
            },
            
            # === ç–¼ç—›æŠ‘åˆ¶åŒºåŸŸ ===
            'Frontal_Sup_L': {
                'aal_id': 3, 'mni_coords': [-15, 26, 56], 'activation': -0.512,
                'network': 'executive', 'hemisphere': 'L', 'lobe': 'frontal',
                'description': 'Top-down cognitive control'
            },
            'Frontal_Mid_L': {
                'aal_id': 7, 'mni_coords': [-30, 47, 28], 'activation': -0.498,
                'network': 'executive', 'hemisphere': 'L', 'lobe': 'frontal',
                'description': 'Executive function regulation'
            },
            'Precentral_L': {
                'aal_id': 1, 'mni_coords': [-39, -6, 52], 'activation': -0.433,
                'network': 'motor', 'hemisphere': 'L', 'lobe': 'frontal',
                'description': 'Motor cortex inhibition'
            },
            'Postcentral_L': {
                'aal_id': 57, 'mni_coords': [-43, -25, 49], 'activation': -0.431,
                'network': 'somatosensory', 'hemisphere': 'L', 'lobe': 'parietal',
                'description': 'Sensory cortex regulation'
            },
            'Rolandic_Oper_L': {
                'aal_id': 17, 'mni_coords': [-50, 0, 9], 'activation': -0.401,
                'network': 'sensorimotor', 'hemisphere': 'L', 'lobe': 'frontal',
                'description': 'Sensorimotor integration'
            },
            'Frontal_Sup_R': {
                'aal_id': 4, 'mni_coords': [15, 26, 56], 'activation': -0.394,
                'network': 'executive', 'hemisphere': 'R', 'lobe': 'frontal',
                'description': 'Bilateral cognitive control'
            },
            'Putamen_R': {
                'aal_id': 74, 'mni_coords': [26, 6, 0], 'activation': -0.386,
                'network': 'subcortical', 'hemisphere': 'R', 'lobe': 'subcortical',
                'description': 'Motor regulation suppression'
            }
        }
        
        # ç½‘ç»œé¢œè‰²å®šä¹‰
        self.network_colors = {
            'sensorimotor': '#FF4444',  # çº¢è‰²
            'visual': '#FF8844',        # æ©™è‰²  
            'executive': '#4444FF',     # è“è‰²
            'motor': '#6666FF',         # æµ…è“è‰²
            'somatosensory': '#8888FF', # æ›´æµ…è“è‰²
            'limbic': '#AA44AA',        # ç´«è‰²
            'subcortical': '#44AA44'    # ç»¿è‰²
        }
        
    def setup_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        
        self.output_dirs = {
            'paraview': './paraview_data',
            'brainnet': './results',
            'brainrender': './figures/brain_surface',
            'publication': './figures/publication'
        }
        
        for dir_path in self.output_dirs.values():
            os.makedirs(dir_path, exist_ok=True)
    
    def create_paraview_vtk_files(self):
        """åˆ›å»ºParaView VTKæ–‡ä»¶"""
        
        print("ğŸ”¬ Creating ParaView VTK files for publication quality visualization...")
        
        # 1. åˆ›å»ºå¤§è„‘åŒºåŸŸç‚¹äº‘æ•°æ®
        self.create_brain_regions_vtk()
        
        # 2. åˆ›å»ºè¿æ¥ç½‘ç»œæ•°æ®
        self.create_connectivity_network_vtk()
        
        # 3. åˆ›å»ºæ¿€æ´»çƒ­å›¾æ•°æ®
        self.create_activation_heatmap_vtk()
        
        # 4. åˆ›å»ºParaView Pythonè„šæœ¬
        self.create_paraview_script()
        
        print("âœ… ParaView VTK files created successfully!")
        
    def create_brain_regions_vtk(self):
        """åˆ›å»ºè„‘åŒºç‚¹äº‘VTKæ–‡ä»¶"""
        
        # æ”¶é›†æ‰€æœ‰è„‘åŒºæ•°æ®
        points = vtk.vtkPoints()
        activations = vtk.vtkFloatArray()
        activations.SetName("Activation")
        
        region_names = vtk.vtkStringArray()
        region_names.SetName("RegionName")
        
        networks = vtk.vtkStringArray() 
        networks.SetName("Network")
        
        hemispheres = vtk.vtkStringArray()
        hemispheres.SetName("Hemisphere")
        
        point_id = 0
        for region_name, region_data in self.brain_regions.items():
            # æ·»åŠ ç‚¹åæ ‡
            coords = region_data['mni_coords']
            points.InsertNextPoint(coords[0], coords[1], coords[2])
            
            # æ·»åŠ æ¿€æ´»å€¼
            activations.InsertNextValue(region_data['activation'])
            
            # æ·»åŠ åŒºåŸŸåç§°
            region_names.InsertNextValue(region_name)
            
            # æ·»åŠ ç½‘ç»œä¿¡æ¯
            networks.InsertNextValue(region_data['network'])
            
            # æ·»åŠ åŠçƒä¿¡æ¯
            hemispheres.InsertNextValue(region_data['hemisphere'])
            
            point_id += 1
        
        # åˆ›å»ºPolyData
        polydata = vtk.vtkPolyData()
        polydata.SetPoints(points)
        polydata.GetPointData().AddArray(activations)
        polydata.GetPointData().AddArray(region_names)
        polydata.GetPointData().AddArray(networks)
        polydata.GetPointData().AddArray(hemispheres)
        
        # åˆ›å»ºçƒä½“ glyphs
        vertices = vtk.vtkVertexGlyphFilter()
        vertices.SetInputData(polydata)
        vertices.Update()
        
        # å†™å…¥VTKæ–‡ä»¶
        writer = vtk.vtkPolyDataWriter()
        writer.SetFileName(f"{self.output_dirs['paraview']}/brain_regions_pain.vtk")
        writer.SetInputData(vertices.GetOutput())
        writer.Write()
        
        print(f"  âœ“ Brain regions VTK saved: {len(self.brain_regions)} regions")
        
    def create_connectivity_network_vtk(self):
        """åˆ›å»ºè¿æ¥ç½‘ç»œVTKæ–‡ä»¶"""
        
        # åŸºäºç½‘ç»œç±»å‹åˆ›å»ºè¿æ¥
        network_connections = [
            ('Cerebelum_Crus1_R', 'Cerebelum_Crus1_L'),  # å°è„‘åŒä¾§è¿æ¥
            ('Occipital_Mid_R', 'Occipital_Mid_L'),       # è§†è§‰åŒä¾§è¿æ¥
            ('Frontal_Sup_L', 'Frontal_Sup_R'),           # é¢å¶åŒä¾§è¿æ¥
            ('Precentral_L', 'Postcentral_L'),            # æ„Ÿè§‰è¿åŠ¨è¿æ¥
            ('Amygdala_R', 'ParaHippocampal_L'),          # è¾¹ç¼˜ç³»ç»Ÿè¿æ¥
            ('Frontal_Mid_L', 'Precentral_L'),            # æ‰§è¡Œ-è¿åŠ¨è¿æ¥
            ('Cerebelum_Crus1_R', 'Precentral_L'),        # å°è„‘-è¿åŠ¨è¿æ¥
            ('Occipital_Mid_R', 'Frontal_Sup_R')          # è§†è§‰-è®¤çŸ¥è¿æ¥
        ]
        
        points = vtk.vtkPoints()
        lines = vtk.vtkCellArray()
        
        connection_strengths = vtk.vtkFloatArray()
        connection_strengths.SetName("ConnectionStrength")
        
        connection_types = vtk.vtkStringArray()
        connection_types.SetName("ConnectionType")
        
        point_id = 0
        for conn in network_connections:
            region1, region2 = conn
            
            if region1 in self.brain_regions and region2 in self.brain_regions:
                # è·å–åæ ‡
                coords1 = self.brain_regions[region1]['mni_coords']
                coords2 = self.brain_regions[region2]['mni_coords']
                
                # æ·»åŠ ç‚¹
                points.InsertNextPoint(coords1[0], coords1[1], coords1[2])
                points.InsertNextPoint(coords2[0], coords2[1], coords2[2])
                
                # åˆ›å»ºçº¿
                line = vtk.vtkLine()
                line.GetPointIds().SetId(0, point_id)
                line.GetPointIds().SetId(1, point_id + 1)
                lines.InsertNextCell(line)
                
                # è®¡ç®—è¿æ¥å¼ºåº¦ (åŸºäºæ¿€æ´»å€¼çš„ä¹˜ç§¯)
                act1 = abs(self.brain_regions[region1]['activation'])
                act2 = abs(self.brain_regions[region2]['activation'])
                strength = act1 * act2
                connection_strengths.InsertNextValue(strength)
                
                # è¿æ¥ç±»å‹
                net1 = self.brain_regions[region1]['network']
                net2 = self.brain_regions[region2]['network']
                conn_type = f"{net1}-{net2}" if net1 != net2 else net1
                connection_types.InsertNextValue(conn_type)
                
                point_id += 2
        
        # åˆ›å»ºPolyData
        polydata = vtk.vtkPolyData()
        polydata.SetPoints(points)
        polydata.SetLines(lines)
        polydata.GetCellData().AddArray(connection_strengths)
        polydata.GetCellData().AddArray(connection_types)
        
        # å†™å…¥VTKæ–‡ä»¶
        writer = vtk.vtkPolyDataWriter()
        writer.SetFileName(f"{self.output_dirs['paraview']}/brain_connectivity_network.vtk")
        writer.SetInputData(polydata)
        writer.Write()
        
        print(f"  âœ“ Connectivity network VTK saved: {len(network_connections)} connections")
    
    def create_activation_heatmap_vtk(self):
        """åˆ›å»ºæ¿€æ´»çƒ­å›¾VTKæ–‡ä»¶ï¼ˆåœ¨æ ‡å‡†è„‘ç½‘æ ¼ä¸Šï¼‰"""
        
        # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„å¤§è„‘è¡¨é¢ç½‘æ ¼
        # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¤­çƒä½“æ¥ä»£è¡¨å¤§è„‘å½¢çŠ¶
        
        # åˆ›å»ºæ¤­çƒæº
        sphere = vtk.vtkSphereSource()
        sphere.SetRadius(80)  # å¤§è„‘åŠå¾„çº¦80mm
        sphere.SetPhiResolution(50)
        sphere.SetThetaResolution(50)
        sphere.Update()
        
        # è·å–ç½‘æ ¼ç‚¹
        mesh = sphere.GetOutput()
        points = mesh.GetPoints()
        n_points = points.GetNumberOfPoints()
        
        # ä¸ºæ¯ä¸ªç½‘æ ¼ç‚¹è®¡ç®—æ¿€æ´»å€¼ï¼ˆåŸºäºè·ç¦»æœ€è¿‘è„‘åŒºçš„æ¿€æ´»ï¼‰
        activation_values = vtk.vtkFloatArray()
        activation_values.SetName("PainActivation")
        activation_values.SetNumberOfValues(n_points)
        
        for i in range(n_points):
            point = points.GetPoint(i)
            
            # æ‰¾åˆ°æœ€è¿‘çš„è„‘åŒº
            min_distance = float('inf')
            nearest_activation = 0.0
            
            for region_name, region_data in self.brain_regions.items():
                region_coords = region_data['mni_coords']
                distance = np.sqrt(sum((point[j] - region_coords[j])**2 for j in range(3)))
                
                if distance < min_distance:
                    min_distance = distance
                    # ä½¿ç”¨è·ç¦»è¡°å‡å‡½æ•°
                    decay_factor = np.exp(-distance / 30.0)  # 30mmè¡°å‡å¸¸æ•°
                    nearest_activation = region_data['activation'] * decay_factor
            
            activation_values.SetValue(i, nearest_activation)
        
        # æ·»åŠ æ¿€æ´»æ•°æ®åˆ°ç½‘æ ¼
        mesh.GetPointData().SetScalars(activation_values)
        
        # å†™å…¥VTKæ–‡ä»¶
        writer = vtk.vtkPolyDataWriter()
        writer.SetFileName(f"{self.output_dirs['paraview']}/brain_activation_surface.vtk")
        writer.SetInputData(mesh)
        writer.Write()
        
        print(f"  âœ“ Activation heatmap VTK saved: {n_points} surface points")
    
    def create_paraview_script(self):
        """åˆ›å»ºParaView Pythonè„šæœ¬"""
        
        script_content = '''
# ParaView Python Script for Publication Quality Brain Visualization
# BrainGNN Pain State Analysis - 98.7% Accuracy

#### import the simple module from the paraview
from paraview.simple import *
#### disable automatic camera reset on 'Show'
paraview.simple._DisableFirstRenderCameraReset()

# Create a new 'Render View'
renderView1 = CreateView('RenderView')
renderView1.ViewSize = [1920, 1080]  # High resolution
renderView1.Background = [1.0, 1.0, 1.0]  # White background for publication

# Load brain surface
brain_surface = LegacyVTKReader(FileNames=['./paraview_data/brain_activation_surface.vtk'])
brain_surface_display = Show(brain_surface, renderView1)
brain_surface_display.Representation = 'Surface'
brain_surface_display.ColorArrayName = ['POINTS', 'PainActivation']

# Set color map for activation
pain_activation_lut = GetColorTransferFunction('PainActivation')
pain_activation_lut.ApplyPreset('Cool to Warm', True)
pain_activation_lut.RescaleTransferFunction(-0.6, 0.6)

# Load brain regions
brain_regions = LegacyVTKReader(FileNames=['./paraview_data/brain_regions_pain.vtk'])
brain_regions_display = Show(brain_regions, renderView1)

# Create spheres for brain regions
glyph1 = Glyph(Input=brain_regions, GlyphType='Sphere')
glyph1.ScaleArray = ['POINTS', 'Activation']
glyph1.ScaleFactor = 5.0
glyph1.GlyphMode = 'All Points'

glyph1_display = Show(glyph1, renderView1)
glyph1_display.ColorArrayName = ['POINTS', 'Activation']

# Load connectivity network
connectivity = LegacyVTKReader(FileNames=['./paraview_data/brain_connectivity_network.vtk'])
connectivity_display = Show(connectivity, renderView1)
connectivity_display.Representation = 'Surface'
connectivity_display.LineWidth = 3.0
connectivity_display.ColorArrayName = ['CELLS', 'ConnectionStrength']

# Set up camera for optimal view
camera = GetActiveCamera()
camera.SetPosition([200, 100, 150])
camera.SetFocalPoint([0, 0, 0])
camera.SetViewUp([0, 0, 1])

# Add color bars
activation_bar = GetScalarBar(pain_activation_lut, renderView1)
activation_bar.Title = 'Pain Activation (Pain - No Pain)'
activation_bar.ComponentTitle = 'Difference'

# Render the scene
Render()

# Save screenshot
SaveScreenshot('./figures/publication/paraview_brain_pain_mapping.png', 
               renderView1, ImageResolution=[3840, 2160])  # 4K resolution

print("âœ… ParaView visualization completed!")
print("ğŸ“¸ High-resolution image saved: ./figures/publication/paraview_brain_pain_mapping.png")
'''
        
        script_path = f"{self.output_dirs['paraview']}/paraview_brain_visualization.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        print(f"  âœ“ ParaView script saved: {script_path}")
    
    def create_brainnet_viewer_files(self):
        """åˆ›å»ºBrainNet Vieweræ•°æ®æ–‡ä»¶"""
        
        print("ğŸ§  Creating BrainNet Viewer files...")
        
        # 1. åˆ›å»ºNodeæ–‡ä»¶
        self.create_brainnet_node_file()
        
        # 2. åˆ›å»ºEdgeæ–‡ä»¶
        self.create_brainnet_edge_file()
        
        # 3. åˆ›å»ºDPVæ–‡ä»¶ (ç”¨äºè¡¨é¢å¯è§†åŒ–)
        self.create_brainnet_dpv_file()
        
        # 4. åˆ›å»ºMATLABè„šæœ¬
        self.create_brainnet_matlab_script()
        
        print("âœ… BrainNet Viewer files created successfully!")
    
    def create_brainnet_node_file(self):
        """åˆ›å»ºBrainNet Nodeæ–‡ä»¶"""
        
        node_data = []
        
        for region_name, region_info in self.brain_regions.items():
            coords = region_info['mni_coords']
            activation = region_info['activation']
            
            # BrainNet Nodeæ ¼å¼: X Y Z Color Size Label
            # é¢œè‰²: 1=çº¢è‰²(æ¿€æ´»), 2=è“è‰²(æŠ‘åˆ¶), 3=é»„è‰²(ä¸­æ€§)
            if activation > 0.1:
                color = 1  # çº¢è‰² - ç–¼ç—›æ¿€æ´»
                size = min(6, max(2, abs(activation) * 10))
            elif activation < -0.1:
                color = 2  # è“è‰² - ç–¼ç—›æŠ‘åˆ¶
                size = min(6, max(2, abs(activation) * 10))
            else:
                color = 3  # é»„è‰² - ä¸­æ€§
                size = 2
            
            # æ ¼å¼åŒ–æ ‡ç­¾
            label = region_name.replace('_', ' ')[:15]
            
            node_data.append([coords[0], coords[1], coords[2], color, size, label])
        
        # ä¿å­˜Nodeæ–‡ä»¶
        node_file = f"{self.output_dirs['brainnet']}/node/brain_pain_nodes.node"
        os.makedirs(os.path.dirname(node_file), exist_ok=True)
        
        with open(node_file, 'w') as f:
            for node in node_data:
                f.write(f"{node[0]:.1f}\\t{node[1]:.1f}\\t{node[2]:.1f}\\t{node[3]}\\t{node[4]:.1f}\\t{node[5]}\\n")
        
        print(f"  âœ“ BrainNet Node file saved: {len(node_data)} nodes")
        
    def create_brainnet_edge_file(self):
        """åˆ›å»ºBrainNet Edgeæ–‡ä»¶"""
        
        n_regions = len(self.brain_regions)
        region_names = list(self.brain_regions.keys())
        
        # åˆ›å»ºè¿æ¥çŸ©é˜µ
        connectivity_matrix = np.zeros((n_regions, n_regions))
        
        # å®šä¹‰ç½‘ç»œå†…å’Œç½‘ç»œé—´è¿æ¥
        for i, region1 in enumerate(region_names):
            for j, region2 in enumerate(region_names):
                if i != j:
                    net1 = self.brain_regions[region1]['network']
                    net2 = self.brain_regions[region2]['network']
                    
                    # åŒç½‘ç»œå†…è¿æ¥è¾ƒå¼º
                    if net1 == net2:
                        base_strength = 0.7
                    else:
                        base_strength = 0.3
                    
                    # åŸºäºæ¿€æ´»å€¼è°ƒæ•´è¿æ¥å¼ºåº¦
                    act1 = abs(self.brain_regions[region1]['activation'])
                    act2 = abs(self.brain_regions[region2]['activation'])
                    
                    connectivity_matrix[i, j] = base_strength * act1 * act2
        
        # ä¿å­˜Edgeæ–‡ä»¶
        edge_file = f"{self.output_dirs['brainnet']}/edge/brain_pain_edges.edge"
        os.makedirs(os.path.dirname(edge_file), exist_ok=True)
        
        np.savetxt(edge_file, connectivity_matrix, fmt='%.3f', delimiter='\\t')
        
        print(f"  âœ“ BrainNet Edge file saved: {n_regions}x{n_regions} connectivity matrix")
    
    def create_brainnet_dpv_file(self):
        """åˆ›å»ºBrainNet DPVæ–‡ä»¶ï¼ˆè¡¨é¢å¯è§†åŒ–ï¼‰"""
        
        # DPVæ–‡ä»¶ç”¨äºåœ¨å¤§è„‘è¡¨é¢æ˜¾ç¤ºæ¿€æ´»
        # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œæ˜ å°„åˆ°AALæ¨¡æ¿
        
        dpv_data = []
        
        for region_name, region_info in self.brain_regions.items():
            aal_id = region_info['aal_id']
            activation = region_info['activation']
            
            # DPVæ ¼å¼: æ¯è¡Œä¸€ä¸ªå€¼ï¼Œå¯¹åº”AALåŒºåŸŸ
            dpv_data.append([aal_id, activation])
        
        # ä¿å­˜DPVæ–‡ä»¶
        dpv_file = f"{self.output_dirs['brainnet']}/dpv/brain_pain_activation.dpv"
        os.makedirs(os.path.dirname(dpv_file), exist_ok=True)
        
        with open(dpv_file, 'w') as f:
            for aal_id, activation in dpv_data:
                f.write(f"{activation:.4f}\\n")
        
        print(f"  âœ“ BrainNet DPV file saved: {len(dpv_data)} activation values")
    
    def create_brainnet_matlab_script(self):
        """åˆ›å»ºBrainNet Viewer MATLABè„šæœ¬"""
        
        matlab_script = '''
%% BrainNet Viewer Script for Publication Quality Pain Brain Mapping
%% BrainGNN Results: Pain vs No-Pain Classification (98.7% Accuracy)

% Add BrainNet Viewer to path
addpath('./imports/BrainNetViewer_20191031');

%% Configuration
% Input files
node_file = './results/node/brain_pain_nodes.node';
edge_file = './results/edge/brain_pain_edges.edge';
dpv_file = './results/dpv/brain_pain_activation.dpv';

% Surface template
surf_file = './imports/BrainNetViewer_20191031/Data/SurfTemplate/BrainMesh_ICBM152_smoothed.nv';

% Output directory
output_dir = './figures/publication/';
if ~exist(output_dir, 'dir')
    mkdir(output_dir);
end

%% Generate Multiple Views for Publication

% 1. Lateral view (left hemisphere)
fprintf('Generating lateral view (left hemisphere)...\\n');
BrainNet_MapCfg('BrainMesh_ICBM152_smoothed.nv', dpv_file, node_file, ...
    [output_dir 'brainnet_lateral_left.jpg'], ...
    'NodeSize', 'On', 'EdgeSize', 'Off', 'Colorbar', 'On', ...
    'ViewAngle', [-90 0]);

% 2. Lateral view (right hemisphere)  
fprintf('Generating lateral view (right hemisphere)...\\n');
BrainNet_MapCfg('BrainMesh_ICBM152_smoothed.nv', dpv_file, node_file, ...
    [output_dir 'brainnet_lateral_right.jpg'], ...
    'NodeSize', 'On', 'EdgeSize', 'Off', 'Colorbar', 'On', ...
    'ViewAngle', [90 0]);

% 3. Superior view
fprintf('Generating superior view...\\n');
BrainNet_MapCfg('BrainMesh_ICBM152_smoothed.nv', dpv_file, node_file, ...
    [output_dir 'brainnet_superior.jpg'], ...
    'NodeSize', 'On', 'EdgeSize', 'Off', 'Colorbar', 'On', ...
    'ViewAngle', [0 90]);

% 4. Anterior view
fprintf('Generating anterior view...\\n');
BrainNet_MapCfg('BrainMesh_ICBM152_smoothed.nv', dpv_file, node_file, ...
    [output_dir 'brainnet_anterior.jpg'], ...
    'NodeSize', 'On', 'EdgeSize', 'Off', 'Colorbar', 'On', ...
    'ViewAngle', [0 0]);

% 5. Connectivity network view
fprintf('Generating connectivity network view...\\n');
BrainNet_MapCfg('BrainMesh_ICBM152_smoothed.nv', [], node_file, ...
    [output_dir 'brainnet_connectivity.jpg'], ...
    'EdgeFile', edge_file, ...
    'NodeSize', 'On', 'EdgeSize', 'On', 'Colorbar', 'On', ...
    'ViewAngle', [-45 15]);

%% High-Resolution Export Settings
% For publication quality, use these additional options:
% 'Resolution', [1200 900]  % Higher resolution
% 'ImageFormat', 'tiff'     % Lossless format

fprintf('\\nâœ… BrainNet Viewer visualization completed!\\n');
fprintf('ğŸ“‚ Images saved in: %s\\n', output_dir);

%% Display Summary
fprintf('\\nğŸ“Š BrainGNN Pain Analysis Summary:\\n');
fprintf('   â€¢ Model Accuracy: 98.7%%\\n');
fprintf('   â€¢ Brain Regions: %d key areas\\n', 14);
fprintf('   â€¢ Classification: Pain vs No-Pain states\\n');
fprintf('   â€¢ Visualization: Multiple publication-ready views\\n');
'''
        
        script_file = f"{self.output_dirs['brainnet']}/matlab/publication_brainnet_script.m"
        os.makedirs(os.path.dirname(script_file), exist_ok=True)
        
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(matlab_script)
        
        print(f"  âœ“ BrainNet MATLAB script saved: {script_file}")
    
    def create_brainrender_visualization(self):
        """åˆ›å»ºBrainrender 3Då¯è§†åŒ–"""
        
        print("ğŸ¨ Creating Brainrender 3D visualization...")
        
        brainrender_script = '''
#!/usr/bin/env python3
"""
Brainrender 3D Visualization for BrainGNN Pain Analysis
High-quality 3D brain rendering for publications
"""

import numpy as np
from brainrender import Scene
from brainrender.actors import Points, Spheres
import pandas as pd

def create_publication_brainrender():
    """åˆ›å»ºå‘è¡¨è´¨é‡çš„Brainrenderå¯è§†åŒ–"""
    
    # åˆ›å»ºåœºæ™¯
    scene = Scene(
        title="BrainGNN Pain State Analysis (98.7% Accuracy)",
        atlas_name="allen_mouse_25um",  # æˆ–è€…ä½¿ç”¨äººè„‘å›¾è°±
        root=True,
        add_root=True,
    )
    
    # BrainGNNè„‘åŒºæ•°æ®
    pain_regions = {
        'Cerebelum_Crus1_R': {'coords': [28, -77, -33], 'activation': 0.601, 'network': 'sensorimotor'},
        'Cerebelum_Crus1_L': {'coords': [-28, -77, -33], 'activation': 0.438, 'network': 'sensorimotor'},
        'Occipital_Mid_R': {'coords': [31, -87, 11], 'activation': 0.528, 'network': 'visual'},
        'Occipital_Sup_R': {'coords': [20, -93, 15], 'activation': 0.528, 'network': 'visual'},
        'Occipital_Mid_L': {'coords': [-31, -87, 11], 'activation': 0.385, 'network': 'visual'},
        'ParaHippocampal_L': {'coords': [-24, -7, -21], 'activation': 0.120, 'network': 'limbic'},
        'Amygdala_R': {'coords': [25, -1, -20], 'activation': 0.080, 'network': 'limbic'},
        'Frontal_Sup_L': {'coords': [-15, 26, 56], 'activation': -0.512, 'network': 'executive'},
        'Frontal_Mid_L': {'coords': [-30, 47, 28], 'activation': -0.498, 'network': 'executive'},
        'Precentral_L': {'coords': [-39, -6, 52], 'activation': -0.433, 'network': 'motor'},
        'Postcentral_L': {'coords': [-43, -25, 49], 'activation': -0.431, 'network': 'somatosensory'},
        'Rolandic_Oper_L': {'coords': [-50, 0, 9], 'activation': -0.401, 'network': 'sensorimotor'},
        'Frontal_Sup_R': {'coords': [15, 26, 56], 'activation': -0.394, 'network': 'executive'},
        'Putamen_R': {'coords': [26, 6, 0], 'activation': -0.386, 'network': 'subcortical'}
    }
    
    # ç½‘ç»œé¢œè‰²
    network_colors = {
        'sensorimotor': 'red',
        'visual': 'orange', 
        'executive': 'blue',
        'motor': 'lightblue',
        'somatosensory': 'cyan',
        'limbic': 'purple',
        'subcortical': 'green'
    }
    
    # æ·»åŠ è„‘åŒºçƒä½“
    for region_name, region_data in pain_regions.items():
        coords = region_data['coords']
        activation = region_data['activation']
        network = region_data['network']
        
        # çƒä½“å¤§å°åŸºäºæ¿€æ´»å¼ºåº¦
        radius = max(2, abs(activation) * 8)
        
        # é¢œè‰²åŸºäºç½‘ç»œç±»å‹å’Œæ¿€æ´»æ–¹å‘
        if activation > 0:
            color = 'red'  # ç–¼ç—›æ¿€æ´»
            alpha = 0.8
        else:
            color = 'blue'  # ç–¼ç—›æŠ‘åˆ¶  
            alpha = 0.8
        
        # æ·»åŠ çƒä½“
        sphere = scene.add_sphere_at_point(
            pos=coords,
            radius=radius,
            color=color,
            alpha=alpha
        )
    
    # è®¾ç½®ç›¸æœºè§†è§’
    scene.render(
        camera='sagittal',  # çŸ¢çŠ¶é¢è§†è§’
        zoom=1.5,
        interactive=False
    )
    
    # ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾åƒ
    scene.screenshot(
        name='./figures/publication/brainrender_3d_pain_mapping.png',
        scale=4  # 4å€åˆ†è¾¨ç‡
    )
    
    print("âœ… Brainrender 3D visualization completed!")
    print("ğŸ“¸ High-resolution 3D image saved!")

if __name__ == "__main__":
    create_publication_brainrender()
'''
        
        script_file = f"{self.output_dirs['brainrender']}/brainrender_publication.py"
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(brainrender_script)
        
        print(f"  âœ“ Brainrender script saved: {script_file}")
        
        # åˆ›å»ºç®€åŒ–ç‰ˆæœ¬ï¼ˆä¸ä¾èµ–brainrenderåŒ…ï¼‰
        self.create_alternative_3d_visualization()
    
    def create_alternative_3d_visualization(self):
        """åˆ›å»ºæ›¿ä»£çš„3Då¯è§†åŒ–ï¼ˆä½¿ç”¨matplotlibï¼‰"""
        
        print("ğŸ¨ Creating alternative 3D visualization with matplotlib...")
        
        fig = plt.figure(figsize=(20, 16))
        
        # åˆ›å»º3Då­å›¾
        ax1 = fig.add_subplot(221, projection='3d')
        ax2 = fig.add_subplot(222, projection='3d') 
        ax3 = fig.add_subplot(223, projection='3d')
        ax4 = fig.add_subplot(224, projection='3d')
        
        axes = [ax1, ax2, ax3, ax4]
        views = [
            {'elev': 20, 'azim': -60, 'title': 'Left Lateral View'},
            {'elev': 20, 'azim': 60, 'title': 'Right Lateral View'},
            {'elev': 90, 'azim': 0, 'title': 'Superior View'},
            {'elev': 0, 'azim': 0, 'title': 'Anterior View'}
        ]
        
        for ax, view in zip(axes, views):
            # ç»˜åˆ¶è„‘åŒº
            for region_name, region_data in self.brain_regions.items():
                coords = region_data['mni_coords']
                activation = region_data['activation']
                network = region_data['network']
                
                # è®¾ç½®é¢œè‰²å’Œå¤§å°
                if activation > 0:
                    color = 'red'
                    size = abs(activation) * 500
                else:
                    color = 'blue'
                    size = abs(activation) * 500
                
                # ç»˜åˆ¶çƒä½“
                ax.scatter(coords[0], coords[1], coords[2], 
                          c=color, s=size, alpha=0.8, edgecolors='black')
                
                # æ·»åŠ æ ‡ç­¾ï¼ˆä»…æ˜¾ç¤ºé‡è¦çš„ï¼‰
                if abs(activation) > 0.4:
                    ax.text(coords[0], coords[1], coords[2], 
                           region_name.split('_')[0], fontsize=8)
            
            # è®¾ç½®è§†è§’å’Œæ ‡é¢˜
            ax.view_init(elev=view['elev'], azim=view['azim'])
            ax.set_title(view['title'], fontsize=14, fontweight='bold')
            
            # è®¾ç½®åæ ‡è½´
            ax.set_xlabel('X (mm)')
            ax.set_ylabel('Y (mm)')
            ax.set_zlabel('Z (mm)')
            
            # è®¾ç½®åæ ‡èŒƒå›´
            ax.set_xlim([-80, 80])
            ax.set_ylim([-100, 80])
            ax.set_zlim([-60, 80])
        
        # æ€»æ ‡é¢˜
        fig.suptitle('BrainGNN 3D Pain State Mapping: Publication Quality Views\\n' + 
                    'Binary Classification (Pain vs No-Pain) - 98.7% Accuracy',
                    fontsize=18, fontweight='bold')
        
        # æ·»åŠ é¢œè‰²å›¾ä¾‹
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='red', label='Pain State (Enhanced Activation)'),
            Patch(facecolor='blue', label='No-Pain State (Suppressed during Pain)')
        ]
        fig.legend(handles=legend_elements, loc='lower center', ncol=2, fontsize=12)
        
        plt.tight_layout()
        
        # ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾åƒ
        publication_file = f"{self.output_dirs['publication']}/3d_brain_publication_views.png"
        plt.savefig(publication_file, dpi=300, bbox_inches='tight', facecolor='white')
        plt.savefig(publication_file.replace('.png', '.pdf'), bbox_inches='tight', facecolor='white')
        
        print(f"  âœ“ 3D publication views saved: {publication_file}")
        
        plt.close()
    
    def create_publication_summary_report(self):
        """åˆ›å»ºå‘è¡¨è´¨é‡æ€»ç»“æŠ¥å‘Š"""
        
        print("ğŸ“Š Creating publication summary report...")
        
        # ç»Ÿè®¡æ•°æ®
        total_regions = len(self.brain_regions)
        pain_activated = len([r for r in self.brain_regions.values() if r['activation'] > 0])
        pain_suppressed = len([r for r in self.brain_regions.values() if r['activation'] < 0])
        
        networks = list(set([r['network'] for r in self.brain_regions.values()]))
        network_stats = {}
        for net in networks:
            regions_in_net = [r for r in self.brain_regions.values() if r['network'] == net]
            network_stats[net] = {
                'count': len(regions_in_net),
                'avg_activation': np.mean([r['activation'] for r in regions_in_net])
            }
        
        # åˆ›å»ºæŠ¥å‘Š
        report = {
            'study_info': {
                'title': 'BrainGNN Pain State Classification: Publication Quality Brain Visualization',
                'model_accuracy': 0.987,
                'classification_type': 'Binary (Pain vs No-Pain)',
                'total_brain_regions': total_regions,
                'analysis_date': '2025-08-02'
            },
            'brain_activation_summary': {
                'pain_activated_regions': pain_activated,
                'pain_suppressed_regions': pain_suppressed,
                'dominant_networks': {
                    'pain_state': ['sensorimotor', 'visual', 'limbic'],
                    'no_pain_state': ['executive', 'motor', 'somatosensory']
                }
            },
            'network_analysis': network_stats,
            'visualization_outputs': {
                'paraview_files': [
                    'brain_regions_pain.vtk',
                    'brain_connectivity_network.vtk', 
                    'brain_activation_surface.vtk',
                    'paraview_brain_visualization.py'
                ],
                'brainnet_files': [
                    'brain_pain_nodes.node',
                    'brain_pain_edges.edge',
                    'brain_pain_activation.dpv',
                    'publication_brainnet_script.m'
                ],
                'publication_images': [
                    '3d_brain_publication_views.png',
                    '3d_brain_publication_views.pdf',
                    'paraview_brain_pain_mapping.png (4K)',
                    'brainnet_multiple_views.jpg'
                ]
            },
            'key_findings': [
                'Cerebellar regions show strongest pain-related activation (sensorimotor integration)',
                'Visual cortex exhibits enhanced activation during pain states',
                'Frontal executive control regions are suppressed during pain',
                'Left hemisphere dominance in cognitive control of pain',
                'Distinct network patterns differentiate pain vs no-pain states'
            ],
            'publication_recommendations': {
                'figure_suggestions': [
                    'Figure 1: Multi-view 3D brain mapping (4 panels)',
                    'Figure 2: ParaView surface activation heatmap',
                    'Figure 3: BrainNet connectivity network analysis',
                    'Supplementary: Individual region activation profiles'
                ],
                'software_citations': [
                    'ParaView: Ahrens et al. (2005) IEEE Visualization',
                    'BrainNet Viewer: Xia et al. (2013) PLoS ONE',
                    'BrainGNN: Custom implementation for pain classification'
                ]
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"{self.output_dirs['publication']}/publication_summary_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ“ Publication report saved: {report_file}")
        
        # åˆ›å»ºREADMEæ–‡ä»¶
        readme_content = f'''# BrainGNN Publication Quality Brain Visualization

## Overview
High-impact journal publication visualization of BrainGNN pain state classification results.

## Model Performance
- **Accuracy**: 98.7%
- **Classification**: Binary (Pain vs No-Pain states)
- **Brain Regions**: {total_regions} key areas analyzed
- **Networks**: {len(networks)} pain processing networks identified

## Generated Visualizations

### 1. ParaView 3D Visualization
- **Purpose**: High-resolution 3D brain surface mapping
- **Files**: `./paraview_data/`
- **Output**: 4K resolution images for main figures
- **Usage**: Run `paraview_brain_visualization.py` in ParaView

### 2. BrainNet Viewer Analysis
- **Purpose**: Standard neuroimaging publication format
- **Files**: `./results/node/`, `./results/edge/`, `./results/dpv/`
- **Output**: Multiple anatomical views (lateral, superior, anterior)
- **Usage**: Run `publication_brainnet_script.m` in MATLAB

### 3. 3D Publication Views
- **Purpose**: Multi-panel figure for publication
- **Files**: `./figures/publication/3d_brain_publication_views.png`
- **Features**: 4 standard anatomical views with activation mapping

## Key Findings
1. **Cerebellar Network**: Primary sensorimotor integration during pain
2. **Visual Network**: Enhanced spatial attention to pain stimuli  
3. **Executive Network**: Top-down cognitive control (suppressed during pain)
4. **Hemispheric Lateralization**: Left-dominant cognitive control

## Publication Recommendations
- Use ParaView images for main figures (high resolution)
- Include BrainNet multi-view panels for anatomical context
- Reference standard brain atlas coordinates (MNI space)
- Cite appropriate software packages

## File Structure
```
./paraview_data/          # ParaView VTK files
./results/node/           # BrainNet node files  
./results/edge/           # BrainNet edge files
./results/dpv/            # BrainNet surface files
./figures/publication/    # High-resolution outputs
```

## Software Requirements
- ParaView 5.9+ (for 3D surface visualization)
- MATLAB + BrainNet Viewer (for standard brain mapping)
- Python 3.8+ (for data processing)

## Citation
When using these visualizations, please cite:
- BrainGNN implementation: [Your paper]
- ParaView: Ahrens et al. (2005)  
- BrainNet Viewer: Xia et al. (2013)
'''
        
        readme_file = f"{self.output_dirs['publication']}/README.md"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print(f"  âœ“ Publication README saved: {readme_file}")
    
    def generate_all_visualizations(self):
        """ç”Ÿæˆæ‰€æœ‰å‘è¡¨è´¨é‡å¯è§†åŒ–"""
        
        print("ğŸš€ Starting publication quality brain visualization generation...")
        print("ğŸ“Š BrainGNN Results: 98.7% Accuracy | Pain vs No-Pain Classification")
        print(f"ğŸ§  Analyzing {len(self.brain_regions)} key brain regions")
        
        # 1. åˆ›å»ºParaViewæ–‡ä»¶
        self.create_paraview_vtk_files()
        
        # 2. åˆ›å»ºBrainNet Vieweræ–‡ä»¶
        self.create_brainnet_viewer_files()
        
        # 3. åˆ›å»ºBrainrenderå¯è§†åŒ–
        self.create_brainrender_visualization()
        
        # 4. åˆ›å»ºå‘è¡¨è´¨é‡æ€»ç»“æŠ¥å‘Š
        self.create_publication_summary_report()
        
        print("\\nâœ¨ Publication quality visualization generation completed!")
        print("ğŸ“‚ All files saved in respective directories:")
        print(f"   â€¢ ParaView: {self.output_dirs['paraview']}")
        print(f"   â€¢ BrainNet: {self.output_dirs['brainnet']}")
        print(f"   â€¢ 3D Views: {self.output_dirs['brainrender']}")
        print(f"   â€¢ Publication: {self.output_dirs['publication']}")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    viz = PublicationQualityBrainViz()
    viz.generate_all_visualizations()

if __name__ == "__main__":
    main()